{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from __future__ import division\n",
    "from scipy.special import erfinv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/test.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000137c73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00021489f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004d7953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00056a333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00056d8eb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4992 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  \\\n",
       "0  000137c73        0.0        0.0        0.0        0.0        0.0   \n",
       "1  00021489f        0.0        0.0        0.0        0.0        0.0   \n",
       "2  0004d7953        0.0        0.0        0.0        0.0        0.0   \n",
       "3  00056a333        0.0        0.0        0.0        0.0        0.0   \n",
       "4  00056d8eb        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   30347e683  d08d1fbe3  6ee66e115  20aa07010    ...      3ecc09859  \\\n",
       "0        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "1        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "2        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "3        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "4        0.0        0.0        0.0        0.0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0  \n",
       "4        0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 4992 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train[\"target\"].values\n",
    "ids_train = df_train[\"ID\"].values\n",
    "df_train = df_train.drop( [ \"ID\" , \"target\"] , axis = 1  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_test = df_test[\"ID\"].values \n",
    "df_test = df_test.drop( [\"ID\"] , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_remove = []\n",
    "for col in df_train.columns:\n",
    "    \n",
    "    if df_train[col].std() == 0:\n",
    "        cols_remove.append( col )\n",
    "        \n",
    "df_train = df_train.drop( cols_remove , axis = 1 )\n",
    "df_test = df_test.drop( cols_remove , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 4735)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_and_zeroes = []\n",
    "for col in df_train.columns:\n",
    "    no_of_zeroes = []\n",
    "    cols_dict = {}\n",
    "    aa = (df_train[col].value_counts())\n",
    "    for key, value in aa.iteritems():\n",
    "        if key==0:\n",
    "            per = float(value * 100 / 4459)\n",
    "            cols_dict[col] = float(per)\n",
    "            cols_and_zeroes.append(cols_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "l= []\n",
    "for i in cols_and_zeroes:\n",
    "    for k,v in i.items():\n",
    "        if v>=99:\n",
    "            l.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2108"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop( l , axis = 1 )\n",
    "df_test = df_test.drop( l , axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 2627)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 2627)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_gauss(x):\n",
    "    # x is numpy vector\n",
    "    N = x.shape[0]\n",
    "    temp = x.argsort()\n",
    "    rank_x = temp.argsort() / N\n",
    "    rank_x -= rank_x.mean()\n",
    "    rank_x *= 2 # rank_x.max(), rank_x.min() should be in (-1, 1)\n",
    "    efi_x = erfinv(rank_x) # np.sqrt(2)*erfinv(rank_x)\n",
    "    efi_x -= efi_x.mean()\n",
    "    return efi_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.apply( rank_gauss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.apply( rank_gauss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>30347e683</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>11d86fa6a</th>\n",
       "      <th>4681de4fd</th>\n",
       "      <th>adf119b9a</th>\n",
       "      <th>b8a716ebf</th>\n",
       "      <th>d966ac62c</th>\n",
       "      <th>68b647452</th>\n",
       "      <th>0d866c3d7</th>\n",
       "      <th>...</th>\n",
       "      <th>8d8bffbae</th>\n",
       "      <th>9437d8b64</th>\n",
       "      <th>5831f4c76</th>\n",
       "      <th>a165f5761</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "      <td>-2.609215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.292764</td>\n",
       "      <td>0.680062</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>0.220560</td>\n",
       "      <td>0.617099</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>0.289303</td>\n",
       "      <td>0.279390</td>\n",
       "      <td>0.259301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228084</td>\n",
       "      <td>0.249971</td>\n",
       "      <td>0.189466</td>\n",
       "      <td>0.283693</td>\n",
       "      <td>0.253782</td>\n",
       "      <td>0.271671</td>\n",
       "      <td>0.187406</td>\n",
       "      <td>0.274240</td>\n",
       "      <td>0.288007</td>\n",
       "      <td>0.274669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.293197</td>\n",
       "      <td>0.144903</td>\n",
       "      <td>0.282401</td>\n",
       "      <td>0.275955</td>\n",
       "      <td>0.220977</td>\n",
       "      <td>0.610725</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.289735</td>\n",
       "      <td>0.279820</td>\n",
       "      <td>0.259727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228503</td>\n",
       "      <td>0.250394</td>\n",
       "      <td>0.189878</td>\n",
       "      <td>0.284124</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.272099</td>\n",
       "      <td>0.187818</td>\n",
       "      <td>0.274669</td>\n",
       "      <td>0.288439</td>\n",
       "      <td>0.275098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293630</td>\n",
       "      <td>0.144497</td>\n",
       "      <td>0.282832</td>\n",
       "      <td>0.276384</td>\n",
       "      <td>0.221395</td>\n",
       "      <td>0.604973</td>\n",
       "      <td>0.249124</td>\n",
       "      <td>0.290167</td>\n",
       "      <td>0.280250</td>\n",
       "      <td>0.260152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228922</td>\n",
       "      <td>0.250817</td>\n",
       "      <td>0.190290</td>\n",
       "      <td>0.284555</td>\n",
       "      <td>0.254630</td>\n",
       "      <td>0.272527</td>\n",
       "      <td>0.188230</td>\n",
       "      <td>0.275098</td>\n",
       "      <td>0.288871</td>\n",
       "      <td>0.275526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294063</td>\n",
       "      <td>0.636530</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.276813</td>\n",
       "      <td>0.221812</td>\n",
       "      <td>0.586270</td>\n",
       "      <td>0.249547</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.280680</td>\n",
       "      <td>0.260577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229341</td>\n",
       "      <td>0.251240</td>\n",
       "      <td>0.190702</td>\n",
       "      <td>0.284986</td>\n",
       "      <td>0.255055</td>\n",
       "      <td>0.272955</td>\n",
       "      <td>0.188642</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>0.289303</td>\n",
       "      <td>0.275955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2627 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   30347e683  20aa07010  dc5a8f1d8  11d86fa6a  4681de4fd  adf119b9a  \\\n",
       "0  -2.609215  -2.609215  -2.609215  -2.609215  -2.609215  -2.609215   \n",
       "1   0.292764   0.680062   0.281971   0.275526   0.220560   0.617099   \n",
       "2   0.293197   0.144903   0.282401   0.275955   0.220977   0.610725   \n",
       "3   0.293630   0.144497   0.282832   0.276384   0.221395   0.604973   \n",
       "4   0.294063   0.636530   0.283262   0.276813   0.221812   0.586270   \n",
       "\n",
       "   b8a716ebf  d966ac62c  68b647452  0d866c3d7    ...      8d8bffbae  \\\n",
       "0  -2.609215  -2.609215  -2.609215  -2.609215    ...      -2.609215   \n",
       "1   0.248279   0.289303   0.279390   0.259301    ...       0.228084   \n",
       "2   0.248702   0.289735   0.279820   0.259727    ...       0.228503   \n",
       "3   0.249124   0.290167   0.280250   0.260152    ...       0.228922   \n",
       "4   0.249547   0.290600   0.280680   0.260577    ...       0.229341   \n",
       "\n",
       "   9437d8b64  5831f4c76  a165f5761  3ecc09859  9281abeea  8675bec0b  \\\n",
       "0  -2.609215  -2.609215  -2.609215  -2.609215  -2.609215  -2.609215   \n",
       "1   0.249971   0.189466   0.283693   0.253782   0.271671   0.187406   \n",
       "2   0.250394   0.189878   0.284124   0.254206   0.272099   0.187818   \n",
       "3   0.250817   0.190290   0.284555   0.254630   0.272527   0.188230   \n",
       "4   0.251240   0.190702   0.284986   0.255055   0.272955   0.188642   \n",
       "\n",
       "   3a13ed79a  7e293fbaf  9fc776466  \n",
       "0  -2.609215  -2.609215  -2.609215  \n",
       "1   0.274240   0.288007   0.274669  \n",
       "2   0.274669   0.288439   0.275098  \n",
       "3   0.275098   0.288871   0.275526  \n",
       "4   0.275526   0.289303   0.275955  \n",
       "\n",
       "[5 rows x 2627 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist (df_train[\"30347e683\"] , normed = True  )\n",
    "plt.hist( df_test[\"30347e683\"] , normed = True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"30347e683\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4459, 2627)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../data/train_norm.csv\" , index = False )\n",
    "df_test.to_csv(\"../data/test_norm.csv\" , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame( np.log( target ) ).to_csv(\"../data/labels_train.csv\" , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.values\n",
    "X_test = df_test.values\n",
    "labels_train = np.log( target.copy() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.32663\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l2: 2.3036\n",
      "2.3035975277069114\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.09292\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 2.06161\n",
      "2.0616095843112396\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.13798\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l2: 2.12385\n",
      "2.1238478294343883\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2149\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's l2: 2.17284\n",
      "2.172843054656511\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.26308\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 2.25698\n",
      "2.2569814162918522\n",
      "cv score:\n",
      "2.183759465002313\n",
      "current score: 2.183759465002313 1\n",
      "[2.3035975277069114, 2.0616095843112396, 2.1238478294343883, 2.172843054656511, 2.2569814162918522]\n",
      "([61, 53, 61, 44, 70], 57.8)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.32991\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 2.30439\n",
      "2.3043918555205396\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.09903\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.06663\n",
      "2.066627614111805\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.20078\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 2.16771\n",
      "2.1677127864747985\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.23633\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 2.19667\n",
      "2.196672433916894\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.257\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 2.23945\n",
      "2.239449754240783\n",
      "cv score:\n",
      "2.194960913776627\n",
      "current score: 2.1763918788394054 2\n",
      "[2.3043918555205396, 2.066627614111805, 2.1677127864747985, 2.196672433916894, 2.239449754240783]\n",
      "([57, 56, 49, 53, 63], 55.6)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.32626\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.30313\n",
      "2.303126114489901\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.08764\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 2.06429\n",
      "2.0642855969637424\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19341\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's l2: 2.14772\n",
      "2.1477166611565983\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.18943\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 2.16541\n",
      "2.1654107630076043\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.28577\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l2: 2.28145\n",
      "2.2814505841137795\n",
      "cv score:\n",
      "2.1923779725087456\n",
      "current score: 2.1732046860574776 3\n",
      "[2.303126114489901, 2.0642855969637424, 2.1477166611565983, 2.1654107630076043, 2.2814505841137795]\n",
      "([56, 57, 50, 53, 94], 62.0)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.29878\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's l2: 2.29298\n",
      "2.2929809012621147\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.12858\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 2.11287\n",
      "2.112873705800271\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.1566\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 2.13191\n",
      "2.1319138861357496\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19603\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l2: 2.17913\n",
      "2.1791278918482337\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2846\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 2.27309\n",
      "2.2730889927933737\n",
      "cv score:\n",
      "2.1979802350393043\n",
      "current score: 2.171712648430542 4\n",
      "[2.2929809012621147, 2.112873705800271, 2.1319138861357496, 2.1791278918482337, 2.2730889927933737]\n",
      "([97, 54, 57, 71, 63], 68.4)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.33353\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's l2: 2.292\n",
      "2.2920004759577646\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.08025\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's l2: 2.06598\n",
      "2.0659750414351814\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.17103\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l2: 2.15425\n",
      "2.154252285634978\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.18668\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 2.16339\n",
      "2.1633871295580174\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.22248\n",
      "[200]\tvalid_0's l2: 2.25004\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's l2: 2.20912\n",
      "2.209118528614268\n",
      "cv score:\n",
      "2.1769394772060937\n",
      "current score: 2.166295124538639 5\n",
      "[2.2920004759577646, 2.0659750414351814, 2.154252285634978, 2.1633871295580174, 2.209118528614268]\n",
      "([50, 82, 65, 54, 111], 72.4)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.28254\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.25969\n",
      "2.2596935314437125\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.09297\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 2.05557\n",
      "2.055567844076735\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.1911\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's l2: 2.15136\n",
      "2.1513642992689195\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.18817\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 2.14108\n",
      "2.141084599850716\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.25821\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 2.25719\n",
      "2.257191120313438\n",
      "cv score:\n",
      "2.1729613934017102\n",
      "current score: 2.1630054904090517 6\n",
      "[2.2596935314437125, 2.055567844076735, 2.1513642992689195, 2.141084599850716, 2.257191120313438]\n",
      "([56, 57, 55, 57, 70], 59.0)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.36201\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.32915\n",
      "2.3291515389231114\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.096\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l2: 2.0722\n",
      "2.0722015104290823\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.17425\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l2: 2.15499\n",
      "2.1549887109190258\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.17716\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l2: 2.14473\n",
      "2.144731448607506\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2578\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's l2: 2.24656\n",
      "2.2465599558493987\n",
      "cv score:\n",
      "2.189513842337214\n",
      "current score: 2.1626439898033385 7\n",
      "[2.3291515389231114, 2.0722015104290823, 2.1549887109190258, 2.144731448607506, 2.2465599558493987]\n",
      "([56, 59, 75, 61, 86], 67.4)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.31302\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 2.28687\n",
      "2.286872317505452\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.10416\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l2: 2.0761\n",
      "2.076098738004669\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.15354\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's l2: 2.13961\n",
      "2.1396055076264644\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19968\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's l2: 2.17213\n",
      "2.1721253314581603\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.24937\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l2: 2.23471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2347116341164566\n",
      "cv score:\n",
      "2.1818708580345993\n",
      "current score: 2.1615420097888416 8\n",
      "[2.286872317505452, 2.076098738004669, 2.1396055076264644, 2.1721253314581603, 2.2347116341164566]\n",
      "([63, 65, 69, 45, 59], 60.2)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.31459\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l2: 2.27848\n",
      "2.2784839255201423\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.11734\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 2.08842\n",
      "2.0884164543015604\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.16911\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l2: 2.14218\n",
      "2.142175373275374\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.21319\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.17171\n",
      "2.171714220276383\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2771\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 2.25655\n",
      "2.256548948638465\n",
      "cv score:\n",
      "2.1874522918784476\n",
      "current score: 2.161479173128037 9\n",
      "[2.2784839255201423, 2.0884164543015604, 2.142175373275374, 2.171714220276383, 2.256548948638465]\n",
      "([64, 70, 59, 56, 70], 63.8)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.36936\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.33503\n",
      "2.335025073009961\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.10136\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's l2: 2.07774\n",
      "2.0777365938317485\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.17464\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 2.15353\n",
      "2.1535301248252594\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19214\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's l2: 2.15961\n",
      "2.1596126918060565\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.27716\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l2: 2.26237\n",
      "2.262372066166093\n",
      "cv score:\n",
      "2.197640796190161\n",
      "current score: 2.1624807057903217 10\n",
      "[2.335025073009961, 2.0777365938317485, 2.1535301248252594, 2.1596126918060565, 2.262372066166093]\n",
      "([56, 69, 58, 66, 75], 64.8)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.32634\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 2.2982\n",
      "2.298201424834413\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.08747\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l2: 2.06836\n",
      "2.0683634151034362\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.17548\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's l2: 2.15663\n",
      "2.1566285498440108\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.14464\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l2: 2.12287\n",
      "2.1228695486185307\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19788\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l2: 2.19338\n",
      "2.193381541601274\n",
      "cv score:\n",
      "2.167883178878647\n",
      "current score: 2.160283345940295 11\n",
      "[2.298201424834413, 2.0683634151034362, 2.1566285498440108, 2.1228695486185307, 2.193381541601274]\n",
      "([58, 62, 82, 60, 93], 71.0)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.35075\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.32316\n",
      "2.32315554088766\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.10534\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's l2: 2.08386\n",
      "2.0838583997267843\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.15656\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l2: 2.14276\n",
      "2.1427555832292855\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2018\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l2: 2.1698\n",
      "2.1698032450239184\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.25464\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l2: 2.24734\n",
      "2.247335121286424\n",
      "cv score:\n",
      "2.19336947811082\n",
      "current score: 2.160739637179474 12\n",
      "[2.32315554088766, 2.0838583997267843, 2.1427555832292855, 2.1698032450239184, 2.247335121286424]\n",
      "([56, 47, 52, 61, 64], 56.0)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.31207\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l2: 2.27257\n",
      "2.272566586082347\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.08353\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l2: 2.06764\n",
      "2.0676355855101294\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19661\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's l2: 2.17063\n",
      "2.170629425222255\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.2288\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l2: 2.1772\n",
      "2.1772022447704438\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.30081\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's l2: 2.26297\n",
      "2.2629743558137143\n",
      "cv score:\n",
      "2.1901853190679517\n",
      "current score: 2.160798582679891 13\n",
      "[2.272566586082347, 2.0676355855101294, 2.170629425222255, 2.1772022447704438, 2.2629743558137143]\n",
      "([61, 65, 51, 60, 48], 57.0)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.31176\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 2.29275\n",
      "2.2927463987551007\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.08043\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's l2: 2.0527\n",
      "2.0527033995866617\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.16304\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 2.14561\n",
      "2.1456126667556688\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.24595\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's l2: 2.20238\n",
      "2.2023775133084853\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.28269\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l2: 2.25681\n",
      "2.2568147126217752\n",
      "cv score:\n",
      "2.190035965392258\n",
      "current score: 2.1609799787088635 14\n",
      "[2.2927463987551007, 2.0527033995866617, 2.1456126667556688, 2.2023775133084853, 2.2568147126217752]\n",
      "([54, 56, 49, 45, 72], 55.2)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.30656\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l2: 2.28096\n",
      "2.2809628339975934\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.0803\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l2: 2.06624\n",
      "2.0662360773721846\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.18831\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 2.15478\n",
      "2.154777183315769\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.20744\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l2: 2.16945\n",
      "2.169446927575898\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.25715\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l2: 2.24337\n",
      "2.2433684632264055\n",
      "cv score:\n",
      "2.1829447491796223\n",
      "current score: 2.1605839427949483 15\n",
      "[2.2809628339975934, 2.0662360773721846, 2.154777183315769, 2.169446927575898, 2.2433684632264055]\n",
      "([77, 64, 49, 65, 79], 66.8)\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.33425\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 2.30597\n",
      "2.305967771774146\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.11168\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l2: 2.09481\n",
      "2.0948080817864616\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.14842\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l2: 2.13413\n",
      "2.1341332314414596\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.19237\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l2: 2.16889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1688920573131703\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 2.27233\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l2: 2.26941\n",
      "2.2694136552149695\n",
      "cv score:\n",
      "2.1946261910163107\n",
      "current score: 2.1608296298223375 16\n",
      "[2.305967771774146, 2.0948080817864616, 2.1341332314414596, 2.1688920573131703, 2.2694136552149695]\n",
      "([54, 84, 77, 52, 52], 63.8)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_leaves = 15\n",
    "min_data_in_leaf = 2000\n",
    "feature_fraction = 0.9\n",
    "num_boost_round = 10000\n",
    "params = {\"objective\": \"regression\",\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"learning_rate\": learning_rate,\n",
    "          \"metric\":[\"l2\"] , \n",
    "          \"num_leaves\": num_leaves,\n",
    "           \"max_bin\": 256,\n",
    "          \"feature_fraction\": feature_fraction,\n",
    "          \"verbosity\": 0,\n",
    "          \"drop_rate\": 0.1,\n",
    "          \"max_drop\": 50,\n",
    "          \"min_child_samples\": 10,\n",
    "          \"min_child_weight\": 150,\n",
    "          \"min_split_gain\": 0,\n",
    "          \"subsample\": 0.9\n",
    "          }\n",
    "NFOLDS = 5\n",
    "kfold = KFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "final_cv_train = np.zeros(len(labels_train))\n",
    "final_cv_pred = np.zeros(len( X_test))\n",
    "x_score = []\n",
    "for s in xrange(16):\n",
    "    cv_train = np.zeros(len(labels_train))\n",
    "    cv_pred = np.zeros(len(X_test))\n",
    "\n",
    "    params['seed'] = s\n",
    "\n",
    "    if True:\n",
    "        kf = kfold.split( X ,   labels_train )\n",
    "\n",
    "        best_trees = []\n",
    "        fold_scores = []\n",
    "\n",
    "        for i, (train_fold, validate) in enumerate(kf):\n",
    "            X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], labels_train[train_fold], labels_train[validate]\n",
    "            dtrain = lgb.Dataset(X_train, label_train)\n",
    "            dvalid = lgb.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "            \n",
    "            \n",
    "            bst = lgb.train(params, dtrain, num_boost_round, valid_sets=dvalid , verbose_eval=100,early_stopping_rounds=100)\n",
    "            best_trees.append(bst.best_iteration)\n",
    "            cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "            cv_train[validate] += bst.predict(X_validate)\n",
    "            \n",
    "            \n",
    "            score = mean_squared_error( label_validate, cv_train[validate] )\n",
    "            print( score )\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        cv_pred /= NFOLDS\n",
    "        final_cv_train += cv_train\n",
    "        final_cv_pred += cv_pred\n",
    "\n",
    "        print(\"cv score:\")\n",
    "        print mean_squared_error(labels_train, cv_train)\n",
    "        print \"current score:\", mean_squared_error( labels_train , final_cv_train / (s + 1.)), s+1\n",
    "        print(fold_scores)\n",
    "        print(best_trees, np.mean(best_trees))\n",
    "\n",
    "        x_score.append(mean_squared_error( labels_train , cv_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = final_cv_pred / 16.0\n",
    "pd.DataFrame({'ID': ids_test, 'target': preds }).to_csv('../data/lgbm3_pred_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres_nn = pd.read_csv(\"../data/preds1.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.620798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.920779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.185871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14.937533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>15.172850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      preds\n",
       "0           0      0  15.620798\n",
       "1           1      1  14.920779\n",
       "2           2      2  15.185871\n",
       "3           3      3  14.937533\n",
       "4           4      4  15.172850"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pres_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'ID': ids_test, 'target':   np.exp( pres_nn[\"preds\"] )   }).to_csv('../data/lgbm3_pred_nn_elu-4k-norm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
